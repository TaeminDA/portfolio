{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Heart_Diease_Classification.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "toc_visible": true,
      "machine_shape": "hm"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ZWjnfM84rNQ1"
      },
      "source": [
        "# Heart Diease Classification"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "SfHnOsj_rmuk"
      },
      "source": [
        "## Import"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lQvgmcl5rmdp"
      },
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "import tensorflow as tf\n",
        "from tensorflow import keras\n",
        "#from timeit import default_timer as timer\n",
        "#from datetime import timedelta"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vfvi-lRJrJzi"
      },
      "source": [
        "heart = pd.read_csv(\"/content/heart.csv\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7ieuY_Vfr8Nn"
      },
      "source": [
        "*   Age : Age of the patient\n",
        "*   Sex : Sex of the patient\n",
        "*   Lexang: exercise induced angina (1 = yes; 0 = no)\n",
        "*   ca: number of major vessels (0-3)\n",
        "\n",
        "*   cp : Chest Pain type chest pain type\n",
        "Value 1: typical angina\n",
        "Value 2: atypical angina\n",
        "Value 3: non-anginal pain\n",
        "Value 4: asymptomatic\n",
        "*   trtbps : resting blood pressure (in mm Hg)\n",
        "*   chol : cholestoral in mg/dl fetched via BMI sensor\n",
        "*   fbs : (fasting blood sugar > 120 mg/dl) (1 = true; 0 = false)\n",
        "*   rest_ecg : resting electrocardiographic results\n",
        "Value 0: normal\n",
        "Value 1: having ST-T wave abnormality (T wave inversions and/or ST elevation or depression of > 0.05 mV)\n",
        "Value 2: showing probable or definite left ventricular hypertrophy by Estes' criteria\n",
        "* thalach : maximum heart rate achieved\n",
        "* target : 0= less chance of heart attack 1= more chance of heart attack"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 204
        },
        "id": "Selo6iJfrhy8",
        "outputId": "7de06065-f5af-4fd2-9999-2c6b25dcd34f"
      },
      "source": [
        "heart.head()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>age</th>\n",
              "      <th>sex</th>\n",
              "      <th>cp</th>\n",
              "      <th>trestbps</th>\n",
              "      <th>chol</th>\n",
              "      <th>fbs</th>\n",
              "      <th>restecg</th>\n",
              "      <th>thalach</th>\n",
              "      <th>exang</th>\n",
              "      <th>oldpeak</th>\n",
              "      <th>slope</th>\n",
              "      <th>ca</th>\n",
              "      <th>thal</th>\n",
              "      <th>target</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>63</td>\n",
              "      <td>1</td>\n",
              "      <td>3</td>\n",
              "      <td>145</td>\n",
              "      <td>233</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>150</td>\n",
              "      <td>0</td>\n",
              "      <td>2.3</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>37</td>\n",
              "      <td>1</td>\n",
              "      <td>2</td>\n",
              "      <td>130</td>\n",
              "      <td>250</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>187</td>\n",
              "      <td>0</td>\n",
              "      <td>3.5</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>2</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>41</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>130</td>\n",
              "      <td>204</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>172</td>\n",
              "      <td>0</td>\n",
              "      <td>1.4</td>\n",
              "      <td>2</td>\n",
              "      <td>0</td>\n",
              "      <td>2</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>56</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>120</td>\n",
              "      <td>236</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>178</td>\n",
              "      <td>0</td>\n",
              "      <td>0.8</td>\n",
              "      <td>2</td>\n",
              "      <td>0</td>\n",
              "      <td>2</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>57</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>120</td>\n",
              "      <td>354</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>163</td>\n",
              "      <td>1</td>\n",
              "      <td>0.6</td>\n",
              "      <td>2</td>\n",
              "      <td>0</td>\n",
              "      <td>2</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "   age  sex  cp  trestbps  chol  fbs  ...  exang  oldpeak  slope  ca  thal  target\n",
              "0   63    1   3       145   233    1  ...      0      2.3      0   0     1       1\n",
              "1   37    1   2       130   250    0  ...      0      3.5      0   0     2       1\n",
              "2   41    0   1       130   204    0  ...      0      1.4      2   0     2       1\n",
              "3   56    1   1       120   236    0  ...      0      0.8      2   0     2       1\n",
              "4   57    0   0       120   354    0  ...      1      0.6      2   0     2       1\n",
              "\n",
              "[5 rows x 14 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 3
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "OuKEJ6lFsyYX",
        "outputId": "718ec9c7-ae70-4b36-e7de-531f5482aa0a"
      },
      "source": [
        "heart.info()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "<class 'pandas.core.frame.DataFrame'>\n",
            "RangeIndex: 303 entries, 0 to 302\n",
            "Data columns (total 14 columns):\n",
            " #   Column    Non-Null Count  Dtype  \n",
            "---  ------    --------------  -----  \n",
            " 0   age       303 non-null    int64  \n",
            " 1   sex       303 non-null    int64  \n",
            " 2   cp        303 non-null    int64  \n",
            " 3   trestbps  303 non-null    int64  \n",
            " 4   chol      303 non-null    int64  \n",
            " 5   fbs       303 non-null    int64  \n",
            " 6   restecg   303 non-null    int64  \n",
            " 7   thalach   303 non-null    int64  \n",
            " 8   exang     303 non-null    int64  \n",
            " 9   oldpeak   303 non-null    float64\n",
            " 10  slope     303 non-null    int64  \n",
            " 11  ca        303 non-null    int64  \n",
            " 12  thal      303 non-null    int64  \n",
            " 13  target    303 non-null    int64  \n",
            "dtypes: float64(1), int64(13)\n",
            "memory usage: 33.3 KB\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "GTLh9FgVrhpU",
        "outputId": "a23fae64-19b9-4542-c400-2b22a79eacc6"
      },
      "source": [
        "for i in heart.columns:\n",
        "  print(i,\"unique value:\")\n",
        "  print(\"=>\", heart[i].unique())\n",
        "  "
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "age unique value:\n",
            "=> [63 37 41 56 57 44 52 54 48 49 64 58 50 66 43 69 59 42 61 40 71 51 65 53\n",
            " 46 45 39 47 62 34 35 29 55 60 67 68 74 76 70 38 77]\n",
            "sex unique value:\n",
            "=> [1 0]\n",
            "cp unique value:\n",
            "=> [3 2 1 0]\n",
            "trestbps unique value:\n",
            "=> [145 130 120 140 172 150 110 135 160 105 125 142 155 104 138 128 108 134\n",
            " 122 115 118 100 124  94 112 102 152 101 132 148 178 129 180 136 126 106\n",
            " 156 170 146 117 200 165 174 192 144 123 154 114 164]\n",
            "chol unique value:\n",
            "=> [233 250 204 236 354 192 294 263 199 168 239 275 266 211 283 219 340 226\n",
            " 247 234 243 302 212 175 417 197 198 177 273 213 304 232 269 360 308 245\n",
            " 208 264 321 325 235 257 216 256 231 141 252 201 222 260 182 303 265 309\n",
            " 186 203 183 220 209 258 227 261 221 205 240 318 298 564 277 214 248 255\n",
            " 207 223 288 160 394 315 246 244 270 195 196 254 126 313 262 215 193 271\n",
            " 268 267 210 295 306 178 242 180 228 149 278 253 342 157 286 229 284 224\n",
            " 206 167 230 335 276 353 225 330 290 172 305 188 282 185 326 274 164 307\n",
            " 249 341 407 217 174 281 289 322 299 300 293 184 409 259 200 327 237 218\n",
            " 319 166 311 169 187 176 241 131]\n",
            "fbs unique value:\n",
            "=> [1 0]\n",
            "restecg unique value:\n",
            "=> [0 1 2]\n",
            "thalach unique value:\n",
            "=> [150 187 172 178 163 148 153 173 162 174 160 139 171 144 158 114 151 161\n",
            " 179 137 157 123 152 168 140 188 125 170 165 142 180 143 182 156 115 149\n",
            " 146 175 186 185 159 130 190 132 147 154 202 166 164 184 122 169 138 111\n",
            " 145 194 131 133 155 167 192 121  96 126 105 181 116 108 129 120 112 128\n",
            " 109 113  99 177 141 136  97 127 103 124  88 195 106  95 117  71 118 134\n",
            "  90]\n",
            "exang unique value:\n",
            "=> [0 1]\n",
            "oldpeak unique value:\n",
            "=> [2.3 3.5 1.4 0.8 0.6 0.4 1.3 0.  0.5 1.6 1.2 0.2 1.8 1.  2.6 1.5 3.  2.4\n",
            " 0.1 1.9 4.2 1.1 2.  0.7 0.3 0.9 3.6 3.1 3.2 2.5 2.2 2.8 3.4 6.2 4.  5.6\n",
            " 2.9 2.1 3.8 4.4]\n",
            "slope unique value:\n",
            "=> [0 2 1]\n",
            "ca unique value:\n",
            "=> [0 2 1 3 4]\n",
            "thal unique value:\n",
            "=> [1 2 3 0]\n",
            "target unique value:\n",
            "=> [1 0]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FVIE_HNlrher"
      },
      "source": [
        "categorical_columns = [\"sex\",\"cp\",\"fbs\",\"restecg\",\"exang\",\"slope\",\"ca\",\"thal\"]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "63tDSp0IriS-"
      },
      "source": [
        "## EDA"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "OjNGxk1CrhVb"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7LOffSzkwGjj"
      },
      "source": [
        "***"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "j80dL4Pyv-OI"
      },
      "source": [
        "## Data Engineering"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "t67Ur6b-tfof"
      },
      "source": [
        "y = heart.target\n",
        "X = heart.drop([\"target\"], axis = 1)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "mLYDE0Fqt_vi"
      },
      "source": [
        "### One Hot Encoding"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3x8esCcFt_Jm"
      },
      "source": [
        "from sklearn.preprocessing import OneHotEncoder\n",
        "ohe = OneHotEncoder(drop='first')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "sszZt7yluE1I"
      },
      "source": [
        "non_categorical = ['age', 'trestbps', 'chol', 'thalach', 'oldpeak']"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Vqm-Z3_RuWCB"
      },
      "source": [
        "ohe_dataset = ohe.fit_transform(heart[categorical_columns])\n",
        "columns_ohe = ohe.get_feature_names(input_features = heart[categorical_columns].columns)\n",
        "ohe_dataset = pd.DataFrame(ohe_dataset.toarray())\n",
        "ohe_dataset.columns = columns_ohe\n",
        "X_OH = pd.concat([X.drop(categorical_columns,axis = 1),ohe_dataset],axis = 1)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 224
        },
        "id": "U538PrSqtv0t",
        "outputId": "0cae757a-274b-49db-cd15-1dc1e3ee1a61"
      },
      "source": [
        "# One Hot Encoding\n",
        "X_OH.head()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>age</th>\n",
              "      <th>trestbps</th>\n",
              "      <th>chol</th>\n",
              "      <th>thalach</th>\n",
              "      <th>oldpeak</th>\n",
              "      <th>sex_1</th>\n",
              "      <th>cp_1</th>\n",
              "      <th>cp_2</th>\n",
              "      <th>cp_3</th>\n",
              "      <th>fbs_1</th>\n",
              "      <th>restecg_1</th>\n",
              "      <th>restecg_2</th>\n",
              "      <th>exang_1</th>\n",
              "      <th>slope_1</th>\n",
              "      <th>slope_2</th>\n",
              "      <th>ca_1</th>\n",
              "      <th>ca_2</th>\n",
              "      <th>ca_3</th>\n",
              "      <th>ca_4</th>\n",
              "      <th>thal_1</th>\n",
              "      <th>thal_2</th>\n",
              "      <th>thal_3</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>63</td>\n",
              "      <td>145</td>\n",
              "      <td>233</td>\n",
              "      <td>150</td>\n",
              "      <td>2.3</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>37</td>\n",
              "      <td>130</td>\n",
              "      <td>250</td>\n",
              "      <td>187</td>\n",
              "      <td>3.5</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>41</td>\n",
              "      <td>130</td>\n",
              "      <td>204</td>\n",
              "      <td>172</td>\n",
              "      <td>1.4</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>56</td>\n",
              "      <td>120</td>\n",
              "      <td>236</td>\n",
              "      <td>178</td>\n",
              "      <td>0.8</td>\n",
              "      <td>1.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>57</td>\n",
              "      <td>120</td>\n",
              "      <td>354</td>\n",
              "      <td>163</td>\n",
              "      <td>0.6</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "   age  trestbps  chol  thalach  oldpeak  ...  ca_3  ca_4  thal_1  thal_2  thal_3\n",
              "0   63       145   233      150      2.3  ...   0.0   0.0     1.0     0.0     0.0\n",
              "1   37       130   250      187      3.5  ...   0.0   0.0     0.0     1.0     0.0\n",
              "2   41       130   204      172      1.4  ...   0.0   0.0     0.0     1.0     0.0\n",
              "3   56       120   236      178      0.8  ...   0.0   0.0     0.0     1.0     0.0\n",
              "4   57       120   354      163      0.6  ...   0.0   0.0     0.0     1.0     0.0\n",
              "\n",
              "[5 rows x 22 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 11
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "PPFlGx_PvKwx"
      },
      "source": [
        "### Normalization"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hc9fbZinvKEI"
      },
      "source": [
        "from sklearn.preprocessing import MinMaxScaler\n",
        "scaler = MinMaxScaler()\n",
        "\n",
        "min_heart = X_OH.min()\n",
        "max_heart = X_OH.max()\n",
        "\n",
        "X_normalized = scaler.fit_transform(X_OH)\n",
        "\n",
        "X_normalized = pd.DataFrame(X_normalized)\n",
        "\n",
        "X_normalized.columns = X_OH.columns"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 224
        },
        "id": "DX9yKXDxvttw",
        "outputId": "cc116825-b5f4-4d94-f119-8ac2938c98d0"
      },
      "source": [
        "X_normalized.head()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>age</th>\n",
              "      <th>trestbps</th>\n",
              "      <th>chol</th>\n",
              "      <th>thalach</th>\n",
              "      <th>oldpeak</th>\n",
              "      <th>sex_1</th>\n",
              "      <th>cp_1</th>\n",
              "      <th>cp_2</th>\n",
              "      <th>cp_3</th>\n",
              "      <th>fbs_1</th>\n",
              "      <th>restecg_1</th>\n",
              "      <th>restecg_2</th>\n",
              "      <th>exang_1</th>\n",
              "      <th>slope_1</th>\n",
              "      <th>slope_2</th>\n",
              "      <th>ca_1</th>\n",
              "      <th>ca_2</th>\n",
              "      <th>ca_3</th>\n",
              "      <th>ca_4</th>\n",
              "      <th>thal_1</th>\n",
              "      <th>thal_2</th>\n",
              "      <th>thal_3</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>0.708333</td>\n",
              "      <td>0.481132</td>\n",
              "      <td>0.244292</td>\n",
              "      <td>0.603053</td>\n",
              "      <td>0.370968</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>0.166667</td>\n",
              "      <td>0.339623</td>\n",
              "      <td>0.283105</td>\n",
              "      <td>0.885496</td>\n",
              "      <td>0.564516</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>0.250000</td>\n",
              "      <td>0.339623</td>\n",
              "      <td>0.178082</td>\n",
              "      <td>0.770992</td>\n",
              "      <td>0.225806</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>0.562500</td>\n",
              "      <td>0.245283</td>\n",
              "      <td>0.251142</td>\n",
              "      <td>0.816794</td>\n",
              "      <td>0.129032</td>\n",
              "      <td>1.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>0.583333</td>\n",
              "      <td>0.245283</td>\n",
              "      <td>0.520548</td>\n",
              "      <td>0.702290</td>\n",
              "      <td>0.096774</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "        age  trestbps      chol   thalach  ...  ca_4  thal_1  thal_2  thal_3\n",
              "0  0.708333  0.481132  0.244292  0.603053  ...   0.0     1.0     0.0     0.0\n",
              "1  0.166667  0.339623  0.283105  0.885496  ...   0.0     0.0     1.0     0.0\n",
              "2  0.250000  0.339623  0.178082  0.770992  ...   0.0     0.0     1.0     0.0\n",
              "3  0.562500  0.245283  0.251142  0.816794  ...   0.0     0.0     1.0     0.0\n",
              "4  0.583333  0.245283  0.520548  0.702290  ...   0.0     0.0     1.0     0.0\n",
              "\n",
              "[5 rows x 22 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 13
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tCObFAvxKwC4"
      },
      "source": [
        "from sklearn.preprocessing import StandardScaler\n",
        "scaler = StandardScaler()\n",
        "\n",
        "min_heart = X_OH.min()\n",
        "max_heart = X_OH.max()\n",
        "\n",
        "X_std = scaler.fit_transform(X_OH)\n",
        "\n",
        "X_std = pd.DataFrame(X_std)\n",
        "\n",
        "X_std.columns = X_OH.columns"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 224
        },
        "id": "pz9skFGoK7vZ",
        "outputId": "f1245c85-13c8-413b-e5b9-fe493bffd0dc"
      },
      "source": [
        "X_std.head()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>age</th>\n",
              "      <th>trestbps</th>\n",
              "      <th>chol</th>\n",
              "      <th>thalach</th>\n",
              "      <th>oldpeak</th>\n",
              "      <th>sex_1</th>\n",
              "      <th>cp_1</th>\n",
              "      <th>cp_2</th>\n",
              "      <th>cp_3</th>\n",
              "      <th>fbs_1</th>\n",
              "      <th>restecg_1</th>\n",
              "      <th>restecg_2</th>\n",
              "      <th>exang_1</th>\n",
              "      <th>slope_1</th>\n",
              "      <th>slope_2</th>\n",
              "      <th>ca_1</th>\n",
              "      <th>ca_2</th>\n",
              "      <th>ca_3</th>\n",
              "      <th>ca_4</th>\n",
              "      <th>thal_1</th>\n",
              "      <th>thal_2</th>\n",
              "      <th>thal_3</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>0.952197</td>\n",
              "      <td>0.763956</td>\n",
              "      <td>-0.256334</td>\n",
              "      <td>0.015443</td>\n",
              "      <td>1.087338</td>\n",
              "      <td>0.681005</td>\n",
              "      <td>-0.444554</td>\n",
              "      <td>-0.634648</td>\n",
              "      <td>3.489114</td>\n",
              "      <td>2.394438</td>\n",
              "      <td>-1.003306</td>\n",
              "      <td>-0.115663</td>\n",
              "      <td>-0.696631</td>\n",
              "      <td>-0.926766</td>\n",
              "      <td>-0.939142</td>\n",
              "      <td>-0.522599</td>\n",
              "      <td>-0.378677</td>\n",
              "      <td>-0.265841</td>\n",
              "      <td>-0.129532</td>\n",
              "      <td>3.979112</td>\n",
              "      <td>-1.100763</td>\n",
              "      <td>-0.793116</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>-1.915313</td>\n",
              "      <td>-0.092738</td>\n",
              "      <td>0.072199</td>\n",
              "      <td>1.633471</td>\n",
              "      <td>2.122573</td>\n",
              "      <td>0.681005</td>\n",
              "      <td>-0.444554</td>\n",
              "      <td>1.575677</td>\n",
              "      <td>-0.286606</td>\n",
              "      <td>-0.417635</td>\n",
              "      <td>0.996705</td>\n",
              "      <td>-0.115663</td>\n",
              "      <td>-0.696631</td>\n",
              "      <td>-0.926766</td>\n",
              "      <td>-0.939142</td>\n",
              "      <td>-0.522599</td>\n",
              "      <td>-0.378677</td>\n",
              "      <td>-0.265841</td>\n",
              "      <td>-0.129532</td>\n",
              "      <td>-0.251312</td>\n",
              "      <td>0.908461</td>\n",
              "      <td>-0.793116</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>-1.474158</td>\n",
              "      <td>-0.092738</td>\n",
              "      <td>-0.816773</td>\n",
              "      <td>0.977514</td>\n",
              "      <td>0.310912</td>\n",
              "      <td>-1.468418</td>\n",
              "      <td>2.249444</td>\n",
              "      <td>-0.634648</td>\n",
              "      <td>-0.286606</td>\n",
              "      <td>-0.417635</td>\n",
              "      <td>-1.003306</td>\n",
              "      <td>-0.115663</td>\n",
              "      <td>-0.696631</td>\n",
              "      <td>-0.926766</td>\n",
              "      <td>1.064802</td>\n",
              "      <td>-0.522599</td>\n",
              "      <td>-0.378677</td>\n",
              "      <td>-0.265841</td>\n",
              "      <td>-0.129532</td>\n",
              "      <td>-0.251312</td>\n",
              "      <td>0.908461</td>\n",
              "      <td>-0.793116</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>0.180175</td>\n",
              "      <td>-0.663867</td>\n",
              "      <td>-0.198357</td>\n",
              "      <td>1.239897</td>\n",
              "      <td>-0.206705</td>\n",
              "      <td>0.681005</td>\n",
              "      <td>2.249444</td>\n",
              "      <td>-0.634648</td>\n",
              "      <td>-0.286606</td>\n",
              "      <td>-0.417635</td>\n",
              "      <td>0.996705</td>\n",
              "      <td>-0.115663</td>\n",
              "      <td>-0.696631</td>\n",
              "      <td>-0.926766</td>\n",
              "      <td>1.064802</td>\n",
              "      <td>-0.522599</td>\n",
              "      <td>-0.378677</td>\n",
              "      <td>-0.265841</td>\n",
              "      <td>-0.129532</td>\n",
              "      <td>-0.251312</td>\n",
              "      <td>0.908461</td>\n",
              "      <td>-0.793116</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>0.290464</td>\n",
              "      <td>-0.663867</td>\n",
              "      <td>2.082050</td>\n",
              "      <td>0.583939</td>\n",
              "      <td>-0.379244</td>\n",
              "      <td>-1.468418</td>\n",
              "      <td>-0.444554</td>\n",
              "      <td>-0.634648</td>\n",
              "      <td>-0.286606</td>\n",
              "      <td>-0.417635</td>\n",
              "      <td>0.996705</td>\n",
              "      <td>-0.115663</td>\n",
              "      <td>1.435481</td>\n",
              "      <td>-0.926766</td>\n",
              "      <td>1.064802</td>\n",
              "      <td>-0.522599</td>\n",
              "      <td>-0.378677</td>\n",
              "      <td>-0.265841</td>\n",
              "      <td>-0.129532</td>\n",
              "      <td>-0.251312</td>\n",
              "      <td>0.908461</td>\n",
              "      <td>-0.793116</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "        age  trestbps      chol  ...    thal_1    thal_2    thal_3\n",
              "0  0.952197  0.763956 -0.256334  ...  3.979112 -1.100763 -0.793116\n",
              "1 -1.915313 -0.092738  0.072199  ... -0.251312  0.908461 -0.793116\n",
              "2 -1.474158 -0.092738 -0.816773  ... -0.251312  0.908461 -0.793116\n",
              "3  0.180175 -0.663867 -0.198357  ... -0.251312  0.908461 -0.793116\n",
              "4  0.290464 -0.663867  2.082050  ... -0.251312  0.908461 -0.793116\n",
              "\n",
              "[5 rows x 22 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 15
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Amj6qMO3wMuO"
      },
      "source": [
        "### Splitting Dataset"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5j4NqfD4wZyD"
      },
      "source": [
        "from sklearn.model_selection import train_test_split "
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZvG_Blv9wUQi"
      },
      "source": [
        "X_train, X_test, y_train, y_test = train_test_split(\n",
        "    X_std, \n",
        "    y, \n",
        "    test_size=0.2,  \n",
        "    random_state=629) \n",
        "\n",
        "X_train_tree, X_test_tree, y_train_tree, y_test_tree = train_test_split(\n",
        "    X, \n",
        "    y, \n",
        "    test_size=0.2,  \n",
        "    random_state=629) "
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "iUqP1Meec2WN"
      },
      "source": [
        "# Binary Classifers"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JvjVyb4rlx-0"
      },
      "source": [
        "from sklearn import metrics"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8YCoAV-EvG_n"
      },
      "source": [
        "## DNN"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "C36EppIix2I0"
      },
      "source": [
        "from tensorflow.keras import regularizers"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vm4noJlEtNVY"
      },
      "source": [
        "val_acc_threshold = 0.93\n",
        "acc_threshold = 0.95"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "A6KlhrF_tVUn"
      },
      "source": [
        "class myCallback(tf.keras.callbacks.Callback): \n",
        "    def on_epoch_end(self, epoch, logs={}): \n",
        "        if((logs.get('accuracy') > acc_threshold) & (logs.get('val_accuracy') > val_acc_threshold)):    \n",
        "          print(\"Reached  val_accuracy, so stopping training!!\".format(acc_threshold))\n",
        "          self.model.stop_training = True"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "h_R8oizhuU5e"
      },
      "source": [
        "callbacks = myCallback()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "FTNngVU3wL5V",
        "outputId": "686312d4-8609-4702-b115-f1ba19aa856a"
      },
      "source": [
        "model = keras.Sequential([\n",
        "                          keras.layers.Dense(256,activation = \"relu\",kernel_regularizer=regularizers.l2(l2=1e-2)),\n",
        "                          keras.layers.BatchNormalization(),\n",
        "                          keras.layers.Dense(128,activation = \"relu\",kernel_regularizer=regularizers.l2(l2=1e-2)),\n",
        "                          keras.layers.BatchNormalization(),\n",
        "                          keras.layers.Dense(64,activation = \"relu\",kernel_regularizer=regularizers.l2(l2=1e-2)),\n",
        "                          keras.layers.BatchNormalization(),\n",
        "                          keras.layers.Dense(16,activation = \"relu\",kernel_regularizer=regularizers.l2(l2=1e-2)),\n",
        "                          keras.layers.BatchNormalization(),\n",
        "                          keras.layers.Dense(1,activation=\"sigmoid\")\n",
        "                          ])\n",
        "## Callback\n",
        "  \n",
        "\n",
        "adam_opt = keras.optimizers.Adam(lr=0.001)\n",
        "model.compile(optimizer=adam_opt,loss = 'binary_crossentropy', metrics=['accuracy'])\n",
        "\n",
        "\n",
        "history = model.fit(X_train,\n",
        "                    y_train,\n",
        "                    epochs=300,\n",
        "                    verbose=1,\n",
        "                    validation_data = (X_test,y_test),\n",
        "                    callbacks=[callbacks])"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/300\n",
            "8/8 [==============================] - 3s 94ms/step - loss: 4.0345 - accuracy: 0.4910 - val_loss: 3.8031 - val_accuracy: 0.8852\n",
            "Epoch 2/300\n",
            "8/8 [==============================] - 0s 11ms/step - loss: 3.5083 - accuracy: 0.8528 - val_loss: 3.7028 - val_accuracy: 0.8852\n",
            "Epoch 3/300\n",
            "8/8 [==============================] - 0s 11ms/step - loss: 3.3951 - accuracy: 0.9165 - val_loss: 3.6095 - val_accuracy: 0.8197\n",
            "Epoch 4/300\n",
            "8/8 [==============================] - 0s 11ms/step - loss: 3.2483 - accuracy: 0.9260 - val_loss: 3.5190 - val_accuracy: 0.8033\n",
            "Epoch 5/300\n",
            "8/8 [==============================] - 0s 10ms/step - loss: 3.1195 - accuracy: 0.9479 - val_loss: 3.4342 - val_accuracy: 0.7869\n",
            "Epoch 6/300\n",
            "8/8 [==============================] - 0s 11ms/step - loss: 2.9889 - accuracy: 0.9787 - val_loss: 3.3443 - val_accuracy: 0.7541\n",
            "Epoch 7/300\n",
            "8/8 [==============================] - 0s 11ms/step - loss: 2.8597 - accuracy: 0.9919 - val_loss: 3.2520 - val_accuracy: 0.7377\n",
            "Epoch 8/300\n",
            "8/8 [==============================] - 0s 12ms/step - loss: 2.7658 - accuracy: 0.9705 - val_loss: 3.1566 - val_accuracy: 0.6885\n",
            "Epoch 9/300\n",
            "8/8 [==============================] - 0s 11ms/step - loss: 2.6435 - accuracy: 0.9830 - val_loss: 3.0568 - val_accuracy: 0.6230\n",
            "Epoch 10/300\n",
            "8/8 [==============================] - 0s 11ms/step - loss: 2.5340 - accuracy: 0.9906 - val_loss: 2.9621 - val_accuracy: 0.5902\n",
            "Epoch 11/300\n",
            "8/8 [==============================] - 0s 11ms/step - loss: 2.4134 - accuracy: 0.9882 - val_loss: 2.8695 - val_accuracy: 0.5738\n",
            "Epoch 12/300\n",
            "8/8 [==============================] - 0s 11ms/step - loss: 2.3000 - accuracy: 0.9864 - val_loss: 2.7754 - val_accuracy: 0.5410\n",
            "Epoch 13/300\n",
            "8/8 [==============================] - 0s 11ms/step - loss: 2.2202 - accuracy: 0.9894 - val_loss: 2.6769 - val_accuracy: 0.5574\n",
            "Epoch 14/300\n",
            "8/8 [==============================] - 0s 11ms/step - loss: 2.1020 - accuracy: 1.0000 - val_loss: 2.5895 - val_accuracy: 0.5574\n",
            "Epoch 15/300\n",
            "8/8 [==============================] - 0s 12ms/step - loss: 2.0002 - accuracy: 0.9953 - val_loss: 2.5057 - val_accuracy: 0.5574\n",
            "Epoch 16/300\n",
            "8/8 [==============================] - 0s 11ms/step - loss: 1.9380 - accuracy: 0.9881 - val_loss: 2.4340 - val_accuracy: 0.5410\n",
            "Epoch 17/300\n",
            "8/8 [==============================] - 0s 10ms/step - loss: 1.8244 - accuracy: 0.9929 - val_loss: 2.3545 - val_accuracy: 0.5410\n",
            "Epoch 18/300\n",
            "8/8 [==============================] - 0s 11ms/step - loss: 1.7291 - accuracy: 1.0000 - val_loss: 2.2748 - val_accuracy: 0.5410\n",
            "Epoch 19/300\n",
            "8/8 [==============================] - 0s 10ms/step - loss: 1.6522 - accuracy: 0.9953 - val_loss: 2.2112 - val_accuracy: 0.5410\n",
            "Epoch 20/300\n",
            "8/8 [==============================] - 0s 10ms/step - loss: 1.5625 - accuracy: 1.0000 - val_loss: 2.1354 - val_accuracy: 0.5410\n",
            "Epoch 21/300\n",
            "8/8 [==============================] - 0s 11ms/step - loss: 1.4995 - accuracy: 0.9928 - val_loss: 2.0821 - val_accuracy: 0.5410\n",
            "Epoch 22/300\n",
            "8/8 [==============================] - 0s 11ms/step - loss: 1.4200 - accuracy: 0.9986 - val_loss: 2.0333 - val_accuracy: 0.5410\n",
            "Epoch 23/300\n",
            "8/8 [==============================] - 0s 13ms/step - loss: 1.3553 - accuracy: 0.9986 - val_loss: 1.9387 - val_accuracy: 0.5410\n",
            "Epoch 24/300\n",
            "8/8 [==============================] - 0s 11ms/step - loss: 1.3111 - accuracy: 0.9877 - val_loss: 1.8801 - val_accuracy: 0.5410\n",
            "Epoch 25/300\n",
            "8/8 [==============================] - 0s 11ms/step - loss: 1.3188 - accuracy: 0.9642 - val_loss: 1.8406 - val_accuracy: 0.5410\n",
            "Epoch 26/300\n",
            "8/8 [==============================] - 0s 11ms/step - loss: 1.2312 - accuracy: 0.9686 - val_loss: 1.7057 - val_accuracy: 0.6066\n",
            "Epoch 27/300\n",
            "8/8 [==============================] - 0s 11ms/step - loss: 1.1763 - accuracy: 0.9825 - val_loss: 1.6488 - val_accuracy: 0.6066\n",
            "Epoch 28/300\n",
            "8/8 [==============================] - 0s 11ms/step - loss: 1.1047 - accuracy: 0.9892 - val_loss: 1.6014 - val_accuracy: 0.6393\n",
            "Epoch 29/300\n",
            "8/8 [==============================] - 0s 11ms/step - loss: 1.0644 - accuracy: 0.9854 - val_loss: 1.6026 - val_accuracy: 0.5738\n",
            "Epoch 30/300\n",
            "8/8 [==============================] - 0s 11ms/step - loss: 1.0035 - accuracy: 1.0000 - val_loss: 1.5714 - val_accuracy: 0.5574\n",
            "Epoch 31/300\n",
            "8/8 [==============================] - 0s 11ms/step - loss: 0.9729 - accuracy: 0.9986 - val_loss: 1.5160 - val_accuracy: 0.6066\n",
            "Epoch 32/300\n",
            "8/8 [==============================] - 0s 11ms/step - loss: 0.9192 - accuracy: 1.0000 - val_loss: 1.4791 - val_accuracy: 0.5738\n",
            "Epoch 33/300\n",
            "8/8 [==============================] - 0s 11ms/step - loss: 0.8871 - accuracy: 0.9980 - val_loss: 1.4548 - val_accuracy: 0.5574\n",
            "Epoch 34/300\n",
            "8/8 [==============================] - 0s 11ms/step - loss: 0.8443 - accuracy: 0.9991 - val_loss: 1.4074 - val_accuracy: 0.6230\n",
            "Epoch 35/300\n",
            "8/8 [==============================] - 0s 11ms/step - loss: 0.8143 - accuracy: 0.9986 - val_loss: 1.3469 - val_accuracy: 0.6066\n",
            "Epoch 36/300\n",
            "8/8 [==============================] - 0s 11ms/step - loss: 0.7807 - accuracy: 0.9955 - val_loss: 1.3315 - val_accuracy: 0.6230\n",
            "Epoch 37/300\n",
            "8/8 [==============================] - 0s 11ms/step - loss: 0.7880 - accuracy: 0.9828 - val_loss: 1.2613 - val_accuracy: 0.7213\n",
            "Epoch 38/300\n",
            "8/8 [==============================] - 0s 11ms/step - loss: 0.7389 - accuracy: 0.9869 - val_loss: 1.2887 - val_accuracy: 0.6885\n",
            "Epoch 39/300\n",
            "8/8 [==============================] - 0s 11ms/step - loss: 0.7963 - accuracy: 0.9431 - val_loss: 1.2452 - val_accuracy: 0.6721\n",
            "Epoch 40/300\n",
            "8/8 [==============================] - 0s 11ms/step - loss: 0.7459 - accuracy: 0.9676 - val_loss: 1.1101 - val_accuracy: 0.7869\n",
            "Epoch 41/300\n",
            "8/8 [==============================] - 0s 11ms/step - loss: 0.7242 - accuracy: 0.9835 - val_loss: 1.1158 - val_accuracy: 0.7541\n",
            "Epoch 42/300\n",
            "8/8 [==============================] - 0s 11ms/step - loss: 0.7154 - accuracy: 0.9810 - val_loss: 1.1603 - val_accuracy: 0.7049\n",
            "Epoch 43/300\n",
            "8/8 [==============================] - 0s 11ms/step - loss: 0.6998 - accuracy: 0.9791 - val_loss: 1.0643 - val_accuracy: 0.8197\n",
            "Epoch 44/300\n",
            "8/8 [==============================] - 0s 11ms/step - loss: 0.6546 - accuracy: 0.9739 - val_loss: 1.0548 - val_accuracy: 0.8197\n",
            "Epoch 45/300\n",
            "8/8 [==============================] - 0s 11ms/step - loss: 0.6093 - accuracy: 0.9943 - val_loss: 1.1045 - val_accuracy: 0.7705\n",
            "Epoch 46/300\n",
            "8/8 [==============================] - 0s 11ms/step - loss: 0.6079 - accuracy: 0.9887 - val_loss: 1.1123 - val_accuracy: 0.7869\n",
            "Epoch 47/300\n",
            "8/8 [==============================] - 0s 11ms/step - loss: 0.5745 - accuracy: 0.9991 - val_loss: 1.1052 - val_accuracy: 0.7377\n",
            "Epoch 48/300\n",
            "8/8 [==============================] - 0s 11ms/step - loss: 0.5602 - accuracy: 0.9937 - val_loss: 1.0320 - val_accuracy: 0.7869\n",
            "Epoch 49/300\n",
            "8/8 [==============================] - 0s 11ms/step - loss: 0.5798 - accuracy: 0.9837 - val_loss: 0.9905 - val_accuracy: 0.7869\n",
            "Epoch 50/300\n",
            "8/8 [==============================] - 0s 11ms/step - loss: 0.5356 - accuracy: 0.9977 - val_loss: 0.9708 - val_accuracy: 0.7541\n",
            "Epoch 51/300\n",
            "8/8 [==============================] - 0s 11ms/step - loss: 0.5158 - accuracy: 0.9936 - val_loss: 0.9788 - val_accuracy: 0.8033\n",
            "Epoch 52/300\n",
            "8/8 [==============================] - 0s 11ms/step - loss: 0.5152 - accuracy: 0.9901 - val_loss: 0.9834 - val_accuracy: 0.7705\n",
            "Epoch 53/300\n",
            "8/8 [==============================] - 0s 11ms/step - loss: 0.5057 - accuracy: 0.9891 - val_loss: 0.9765 - val_accuracy: 0.8033\n",
            "Epoch 54/300\n",
            "8/8 [==============================] - 0s 11ms/step - loss: 0.5552 - accuracy: 0.9684 - val_loss: 0.9810 - val_accuracy: 0.8033\n",
            "Epoch 55/300\n",
            "8/8 [==============================] - 0s 11ms/step - loss: 0.4859 - accuracy: 0.9871 - val_loss: 1.0353 - val_accuracy: 0.7213\n",
            "Epoch 56/300\n",
            "8/8 [==============================] - 0s 10ms/step - loss: 0.4640 - accuracy: 0.9936 - val_loss: 1.0087 - val_accuracy: 0.6885\n",
            "Epoch 57/300\n",
            "8/8 [==============================] - 0s 10ms/step - loss: 0.4632 - accuracy: 0.9862 - val_loss: 0.9308 - val_accuracy: 0.7377\n",
            "Epoch 58/300\n",
            "8/8 [==============================] - 0s 11ms/step - loss: 0.4880 - accuracy: 0.9759 - val_loss: 0.9943 - val_accuracy: 0.7541\n",
            "Epoch 59/300\n",
            "8/8 [==============================] - 0s 11ms/step - loss: 0.4262 - accuracy: 1.0000 - val_loss: 0.9545 - val_accuracy: 0.7705\n",
            "Epoch 60/300\n",
            "8/8 [==============================] - 0s 11ms/step - loss: 0.4205 - accuracy: 0.9946 - val_loss: 0.9462 - val_accuracy: 0.8033\n",
            "Epoch 61/300\n",
            "8/8 [==============================] - 0s 11ms/step - loss: 0.4142 - accuracy: 0.9882 - val_loss: 0.9325 - val_accuracy: 0.7705\n",
            "Epoch 62/300\n",
            "8/8 [==============================] - 0s 10ms/step - loss: 0.3869 - accuracy: 0.9953 - val_loss: 0.9095 - val_accuracy: 0.7541\n",
            "Epoch 63/300\n",
            "8/8 [==============================] - 0s 11ms/step - loss: 0.4979 - accuracy: 0.9522 - val_loss: 0.9264 - val_accuracy: 0.8197\n",
            "Epoch 64/300\n",
            "8/8 [==============================] - 0s 11ms/step - loss: 0.3999 - accuracy: 0.9815 - val_loss: 0.9716 - val_accuracy: 0.7869\n",
            "Epoch 65/300\n",
            "8/8 [==============================] - 0s 11ms/step - loss: 0.3807 - accuracy: 0.9870 - val_loss: 1.0689 - val_accuracy: 0.7377\n",
            "Epoch 66/300\n",
            "8/8 [==============================] - 0s 11ms/step - loss: 0.3675 - accuracy: 0.9958 - val_loss: 1.0906 - val_accuracy: 0.7049\n",
            "Epoch 67/300\n",
            "8/8 [==============================] - 0s 11ms/step - loss: 0.3936 - accuracy: 0.9723 - val_loss: 1.0484 - val_accuracy: 0.7377\n",
            "Epoch 68/300\n",
            "8/8 [==============================] - 0s 11ms/step - loss: 0.3643 - accuracy: 0.9884 - val_loss: 1.0277 - val_accuracy: 0.7869\n",
            "Epoch 69/300\n",
            "8/8 [==============================] - 0s 11ms/step - loss: 0.3693 - accuracy: 0.9858 - val_loss: 0.9720 - val_accuracy: 0.7541\n",
            "Epoch 70/300\n",
            "8/8 [==============================] - 0s 11ms/step - loss: 0.3500 - accuracy: 0.9955 - val_loss: 0.9918 - val_accuracy: 0.7705\n",
            "Epoch 71/300\n",
            "8/8 [==============================] - 0s 11ms/step - loss: 0.3334 - accuracy: 0.9991 - val_loss: 0.9403 - val_accuracy: 0.7377\n",
            "Epoch 72/300\n",
            "8/8 [==============================] - 0s 11ms/step - loss: 0.3418 - accuracy: 0.9803 - val_loss: 0.8601 - val_accuracy: 0.7869\n",
            "Epoch 73/300\n",
            "8/8 [==============================] - 0s 10ms/step - loss: 0.3214 - accuracy: 0.9967 - val_loss: 0.8676 - val_accuracy: 0.8197\n",
            "Epoch 74/300\n",
            "8/8 [==============================] - 0s 11ms/step - loss: 0.3505 - accuracy: 0.9879 - val_loss: 1.0741 - val_accuracy: 0.7869\n",
            "Epoch 75/300\n",
            "8/8 [==============================] - 0s 11ms/step - loss: 0.3338 - accuracy: 0.9946 - val_loss: 1.0944 - val_accuracy: 0.8033\n",
            "Epoch 76/300\n",
            "8/8 [==============================] - 0s 10ms/step - loss: 0.3167 - accuracy: 0.9936 - val_loss: 1.0689 - val_accuracy: 0.7541\n",
            "Epoch 77/300\n",
            "8/8 [==============================] - 0s 11ms/step - loss: 0.3014 - accuracy: 0.9939 - val_loss: 1.0557 - val_accuracy: 0.7541\n",
            "Epoch 78/300\n",
            "8/8 [==============================] - 0s 11ms/step - loss: 0.3010 - accuracy: 0.9958 - val_loss: 1.0264 - val_accuracy: 0.7541\n",
            "Epoch 79/300\n",
            "8/8 [==============================] - 0s 11ms/step - loss: 0.3149 - accuracy: 0.9866 - val_loss: 1.0231 - val_accuracy: 0.7869\n",
            "Epoch 80/300\n",
            "8/8 [==============================] - 0s 11ms/step - loss: 0.2831 - accuracy: 0.9973 - val_loss: 1.0726 - val_accuracy: 0.7705\n",
            "Epoch 81/300\n",
            "8/8 [==============================] - 0s 11ms/step - loss: 0.2849 - accuracy: 0.9953 - val_loss: 0.9648 - val_accuracy: 0.7705\n",
            "Epoch 82/300\n",
            "8/8 [==============================] - 0s 11ms/step - loss: 0.2918 - accuracy: 0.9931 - val_loss: 0.8213 - val_accuracy: 0.8361\n",
            "Epoch 83/300\n",
            "8/8 [==============================] - 0s 11ms/step - loss: 0.2940 - accuracy: 0.9933 - val_loss: 0.8623 - val_accuracy: 0.8033\n",
            "Epoch 84/300\n",
            "8/8 [==============================] - 0s 11ms/step - loss: 0.2726 - accuracy: 0.9932 - val_loss: 0.9317 - val_accuracy: 0.7705\n",
            "Epoch 85/300\n",
            "8/8 [==============================] - 0s 11ms/step - loss: 0.3001 - accuracy: 0.9718 - val_loss: 1.0930 - val_accuracy: 0.7541\n",
            "Epoch 86/300\n",
            "8/8 [==============================] - 0s 11ms/step - loss: 0.2846 - accuracy: 0.9856 - val_loss: 1.1655 - val_accuracy: 0.7705\n",
            "Epoch 87/300\n",
            "8/8 [==============================] - 0s 11ms/step - loss: 0.2782 - accuracy: 0.9892 - val_loss: 1.0937 - val_accuracy: 0.7705\n",
            "Epoch 88/300\n",
            "8/8 [==============================] - 0s 11ms/step - loss: 0.2664 - accuracy: 0.9913 - val_loss: 0.8114 - val_accuracy: 0.8525\n",
            "Epoch 89/300\n",
            "8/8 [==============================] - 0s 10ms/step - loss: 0.2888 - accuracy: 0.9875 - val_loss: 0.8845 - val_accuracy: 0.8033\n",
            "Epoch 90/300\n",
            "8/8 [==============================] - 0s 11ms/step - loss: 0.2644 - accuracy: 0.9960 - val_loss: 1.0070 - val_accuracy: 0.7541\n",
            "Epoch 91/300\n",
            "8/8 [==============================] - 0s 11ms/step - loss: 0.2536 - accuracy: 0.9946 - val_loss: 0.9982 - val_accuracy: 0.7705\n",
            "Epoch 92/300\n",
            "8/8 [==============================] - 0s 11ms/step - loss: 0.2574 - accuracy: 0.9871 - val_loss: 0.8615 - val_accuracy: 0.7869\n",
            "Epoch 93/300\n",
            "8/8 [==============================] - 0s 11ms/step - loss: 0.2537 - accuracy: 0.9959 - val_loss: 1.0294 - val_accuracy: 0.7377\n",
            "Epoch 94/300\n",
            "8/8 [==============================] - 0s 13ms/step - loss: 0.2728 - accuracy: 0.9807 - val_loss: 1.1760 - val_accuracy: 0.7377\n",
            "Epoch 95/300\n",
            "8/8 [==============================] - 0s 12ms/step - loss: 0.2606 - accuracy: 0.9926 - val_loss: 1.0814 - val_accuracy: 0.7869\n",
            "Epoch 96/300\n",
            "8/8 [==============================] - 0s 11ms/step - loss: 0.2715 - accuracy: 0.9771 - val_loss: 1.1129 - val_accuracy: 0.7541\n",
            "Epoch 97/300\n",
            "8/8 [==============================] - 0s 31ms/step - loss: 0.2835 - accuracy: 0.9763 - val_loss: 1.1873 - val_accuracy: 0.7541\n",
            "Epoch 98/300\n",
            "8/8 [==============================] - 0s 11ms/step - loss: 0.2278 - accuracy: 0.9971 - val_loss: 1.1941 - val_accuracy: 0.7377\n",
            "Epoch 99/300\n",
            "8/8 [==============================] - 0s 11ms/step - loss: 0.2198 - accuracy: 1.0000 - val_loss: 1.1257 - val_accuracy: 0.7705\n",
            "Epoch 100/300\n",
            "8/8 [==============================] - 0s 11ms/step - loss: 0.2473 - accuracy: 0.9885 - val_loss: 1.0517 - val_accuracy: 0.7705\n",
            "Epoch 101/300\n",
            "8/8 [==============================] - 0s 11ms/step - loss: 0.2506 - accuracy: 0.9792 - val_loss: 0.9856 - val_accuracy: 0.7869\n",
            "Epoch 102/300\n",
            "8/8 [==============================] - 0s 11ms/step - loss: 0.2387 - accuracy: 0.9836 - val_loss: 0.9371 - val_accuracy: 0.7869\n",
            "Epoch 103/300\n",
            "8/8 [==============================] - 0s 11ms/step - loss: 0.2369 - accuracy: 0.9854 - val_loss: 1.2010 - val_accuracy: 0.7377\n",
            "Epoch 104/300\n",
            "8/8 [==============================] - 0s 11ms/step - loss: 0.2179 - accuracy: 0.9958 - val_loss: 1.2228 - val_accuracy: 0.7541\n",
            "Epoch 105/300\n",
            "8/8 [==============================] - 0s 11ms/step - loss: 0.2144 - accuracy: 0.9887 - val_loss: 1.1619 - val_accuracy: 0.7705\n",
            "Epoch 106/300\n",
            "8/8 [==============================] - 0s 11ms/step - loss: 0.2483 - accuracy: 0.9741 - val_loss: 1.1757 - val_accuracy: 0.7869\n",
            "Epoch 107/300\n",
            "8/8 [==============================] - 0s 11ms/step - loss: 0.2761 - accuracy: 0.9703 - val_loss: 1.1504 - val_accuracy: 0.7541\n",
            "Epoch 108/300\n",
            "8/8 [==============================] - 0s 11ms/step - loss: 0.2036 - accuracy: 0.9964 - val_loss: 1.1161 - val_accuracy: 0.7705\n",
            "Epoch 109/300\n",
            "8/8 [==============================] - 0s 11ms/step - loss: 0.1961 - accuracy: 1.0000 - val_loss: 1.2690 - val_accuracy: 0.7049\n",
            "Epoch 110/300\n",
            "8/8 [==============================] - 0s 11ms/step - loss: 0.2018 - accuracy: 0.9944 - val_loss: 1.2450 - val_accuracy: 0.7377\n",
            "Epoch 111/300\n",
            "8/8 [==============================] - 0s 11ms/step - loss: 0.1938 - accuracy: 0.9964 - val_loss: 1.1027 - val_accuracy: 0.8033\n",
            "Epoch 112/300\n",
            "8/8 [==============================] - 0s 11ms/step - loss: 0.2000 - accuracy: 0.9925 - val_loss: 1.0843 - val_accuracy: 0.8033\n",
            "Epoch 113/300\n",
            "8/8 [==============================] - 0s 12ms/step - loss: 0.1846 - accuracy: 0.9982 - val_loss: 1.1709 - val_accuracy: 0.7541\n",
            "Epoch 114/300\n",
            "8/8 [==============================] - 0s 11ms/step - loss: 0.1984 - accuracy: 0.9911 - val_loss: 1.2844 - val_accuracy: 0.7705\n",
            "Epoch 115/300\n",
            "8/8 [==============================] - 0s 11ms/step - loss: 0.1968 - accuracy: 0.9944 - val_loss: 1.2739 - val_accuracy: 0.7541\n",
            "Epoch 116/300\n",
            "8/8 [==============================] - 0s 11ms/step - loss: 0.2051 - accuracy: 0.9821 - val_loss: 1.0564 - val_accuracy: 0.8033\n",
            "Epoch 117/300\n",
            "8/8 [==============================] - 0s 10ms/step - loss: 0.2123 - accuracy: 0.9742 - val_loss: 1.1257 - val_accuracy: 0.7705\n",
            "Epoch 118/300\n",
            "8/8 [==============================] - 0s 11ms/step - loss: 0.2114 - accuracy: 0.9902 - val_loss: 1.3082 - val_accuracy: 0.7869\n",
            "Epoch 119/300\n",
            "8/8 [==============================] - 0s 11ms/step - loss: 0.2107 - accuracy: 0.9795 - val_loss: 1.5636 - val_accuracy: 0.7377\n",
            "Epoch 120/300\n",
            "8/8 [==============================] - 0s 12ms/step - loss: 0.2219 - accuracy: 0.9787 - val_loss: 1.3723 - val_accuracy: 0.7869\n",
            "Epoch 121/300\n",
            "8/8 [==============================] - 0s 11ms/step - loss: 0.2111 - accuracy: 0.9871 - val_loss: 1.4459 - val_accuracy: 0.7705\n",
            "Epoch 122/300\n",
            "8/8 [==============================] - 0s 11ms/step - loss: 0.2268 - accuracy: 0.9857 - val_loss: 1.6296 - val_accuracy: 0.7049\n",
            "Epoch 123/300\n",
            "8/8 [==============================] - 0s 10ms/step - loss: 0.2869 - accuracy: 0.9590 - val_loss: 1.4247 - val_accuracy: 0.7377\n",
            "Epoch 124/300\n",
            "8/8 [==============================] - 0s 11ms/step - loss: 0.2046 - accuracy: 0.9900 - val_loss: 1.2541 - val_accuracy: 0.7705\n",
            "Epoch 125/300\n",
            "8/8 [==============================] - 0s 11ms/step - loss: 0.2002 - accuracy: 0.9986 - val_loss: 1.1468 - val_accuracy: 0.8197\n",
            "Epoch 126/300\n",
            "8/8 [==============================] - 0s 11ms/step - loss: 0.2200 - accuracy: 0.9735 - val_loss: 1.1111 - val_accuracy: 0.7705\n",
            "Epoch 127/300\n",
            "8/8 [==============================] - 0s 11ms/step - loss: 0.1911 - accuracy: 0.9921 - val_loss: 1.1090 - val_accuracy: 0.7377\n",
            "Epoch 128/300\n",
            "8/8 [==============================] - 0s 10ms/step - loss: 0.1791 - accuracy: 1.0000 - val_loss: 1.0546 - val_accuracy: 0.7705\n",
            "Epoch 129/300\n",
            "8/8 [==============================] - 0s 11ms/step - loss: 0.1695 - accuracy: 1.0000 - val_loss: 1.0169 - val_accuracy: 0.7869\n",
            "Epoch 130/300\n",
            "8/8 [==============================] - 0s 11ms/step - loss: 0.1665 - accuracy: 1.0000 - val_loss: 0.9981 - val_accuracy: 0.7869\n",
            "Epoch 131/300\n",
            "8/8 [==============================] - 0s 11ms/step - loss: 0.1604 - accuracy: 1.0000 - val_loss: 0.9635 - val_accuracy: 0.8033\n",
            "Epoch 132/300\n",
            "8/8 [==============================] - 0s 11ms/step - loss: 0.1728 - accuracy: 0.9980 - val_loss: 0.9865 - val_accuracy: 0.7869\n",
            "Epoch 133/300\n",
            "8/8 [==============================] - 0s 11ms/step - loss: 0.1564 - accuracy: 0.9980 - val_loss: 1.0367 - val_accuracy: 0.7377\n",
            "Epoch 134/300\n",
            "8/8 [==============================] - 0s 11ms/step - loss: 0.1566 - accuracy: 0.9972 - val_loss: 1.0998 - val_accuracy: 0.7213\n",
            "Epoch 135/300\n",
            "8/8 [==============================] - 0s 11ms/step - loss: 0.1791 - accuracy: 0.9886 - val_loss: 1.0986 - val_accuracy: 0.7213\n",
            "Epoch 136/300\n",
            "8/8 [==============================] - 0s 11ms/step - loss: 0.1521 - accuracy: 0.9945 - val_loss: 0.9476 - val_accuracy: 0.8033\n",
            "Epoch 137/300\n",
            "8/8 [==============================] - 0s 11ms/step - loss: 0.1897 - accuracy: 0.9829 - val_loss: 1.0834 - val_accuracy: 0.7869\n",
            "Epoch 138/300\n",
            "8/8 [==============================] - 0s 12ms/step - loss: 0.2026 - accuracy: 0.9876 - val_loss: 1.1082 - val_accuracy: 0.7705\n",
            "Epoch 139/300\n",
            "8/8 [==============================] - 0s 11ms/step - loss: 0.1975 - accuracy: 0.9890 - val_loss: 0.8961 - val_accuracy: 0.8197\n",
            "Epoch 140/300\n",
            "8/8 [==============================] - 0s 11ms/step - loss: 0.2220 - accuracy: 0.9686 - val_loss: 1.1520 - val_accuracy: 0.7213\n",
            "Epoch 141/300\n",
            "8/8 [==============================] - 0s 12ms/step - loss: 0.2201 - accuracy: 0.9783 - val_loss: 1.3369 - val_accuracy: 0.7213\n",
            "Epoch 142/300\n",
            "8/8 [==============================] - 0s 11ms/step - loss: 0.2029 - accuracy: 0.9820 - val_loss: 1.3880 - val_accuracy: 0.7541\n",
            "Epoch 143/300\n",
            "8/8 [==============================] - 0s 11ms/step - loss: 0.2113 - accuracy: 0.9795 - val_loss: 1.3270 - val_accuracy: 0.7377\n",
            "Epoch 144/300\n",
            "8/8 [==============================] - 0s 11ms/step - loss: 0.2256 - accuracy: 0.9752 - val_loss: 1.2122 - val_accuracy: 0.8033\n",
            "Epoch 145/300\n",
            "8/8 [==============================] - 0s 11ms/step - loss: 0.2242 - accuracy: 0.9624 - val_loss: 1.1996 - val_accuracy: 0.7869\n",
            "Epoch 146/300\n",
            "8/8 [==============================] - 0s 13ms/step - loss: 0.1827 - accuracy: 0.9991 - val_loss: 1.1742 - val_accuracy: 0.8033\n",
            "Epoch 147/300\n",
            "8/8 [==============================] - 0s 12ms/step - loss: 0.1874 - accuracy: 0.9977 - val_loss: 1.1281 - val_accuracy: 0.7705\n",
            "Epoch 148/300\n",
            "8/8 [==============================] - 0s 11ms/step - loss: 0.2270 - accuracy: 0.9752 - val_loss: 1.0304 - val_accuracy: 0.7869\n",
            "Epoch 149/300\n",
            "8/8 [==============================] - 0s 11ms/step - loss: 0.1788 - accuracy: 0.9964 - val_loss: 1.0050 - val_accuracy: 0.8033\n",
            "Epoch 150/300\n",
            "8/8 [==============================] - 0s 11ms/step - loss: 0.1724 - accuracy: 0.9957 - val_loss: 1.1799 - val_accuracy: 0.7869\n",
            "Epoch 151/300\n",
            "8/8 [==============================] - 0s 11ms/step - loss: 0.2034 - accuracy: 0.9887 - val_loss: 1.3523 - val_accuracy: 0.7541\n",
            "Epoch 152/300\n",
            "8/8 [==============================] - 0s 11ms/step - loss: 0.2195 - accuracy: 0.9824 - val_loss: 1.1962 - val_accuracy: 0.7541\n",
            "Epoch 153/300\n",
            "8/8 [==============================] - 0s 11ms/step - loss: 0.1649 - accuracy: 1.0000 - val_loss: 1.0966 - val_accuracy: 0.7705\n",
            "Epoch 154/300\n",
            "8/8 [==============================] - 0s 12ms/step - loss: 0.1809 - accuracy: 0.9944 - val_loss: 1.2356 - val_accuracy: 0.7541\n",
            "Epoch 155/300\n",
            "8/8 [==============================] - 0s 11ms/step - loss: 0.2248 - accuracy: 0.9681 - val_loss: 0.9852 - val_accuracy: 0.8197\n",
            "Epoch 156/300\n",
            "8/8 [==============================] - 0s 11ms/step - loss: 0.1646 - accuracy: 0.9950 - val_loss: 1.0731 - val_accuracy: 0.7869\n",
            "Epoch 157/300\n",
            "8/8 [==============================] - 0s 11ms/step - loss: 0.2001 - accuracy: 0.9789 - val_loss: 1.1412 - val_accuracy: 0.7869\n",
            "Epoch 158/300\n",
            "8/8 [==============================] - 0s 11ms/step - loss: 0.2044 - accuracy: 0.9901 - val_loss: 1.2653 - val_accuracy: 0.7541\n",
            "Epoch 159/300\n",
            "8/8 [==============================] - 0s 11ms/step - loss: 0.1627 - accuracy: 0.9991 - val_loss: 1.2616 - val_accuracy: 0.7541\n",
            "Epoch 160/300\n",
            "8/8 [==============================] - 0s 11ms/step - loss: 0.1564 - accuracy: 1.0000 - val_loss: 1.2520 - val_accuracy: 0.7705\n",
            "Epoch 161/300\n",
            "8/8 [==============================] - 0s 11ms/step - loss: 0.1615 - accuracy: 0.9980 - val_loss: 1.1785 - val_accuracy: 0.7869\n",
            "Epoch 162/300\n",
            "8/8 [==============================] - 0s 11ms/step - loss: 0.1568 - accuracy: 0.9936 - val_loss: 1.1601 - val_accuracy: 0.7869\n",
            "Epoch 163/300\n",
            "8/8 [==============================] - 0s 11ms/step - loss: 0.1705 - accuracy: 0.9964 - val_loss: 1.2777 - val_accuracy: 0.7377\n",
            "Epoch 164/300\n",
            "8/8 [==============================] - 0s 11ms/step - loss: 0.1493 - accuracy: 0.9986 - val_loss: 1.3933 - val_accuracy: 0.7377\n",
            "Epoch 165/300\n",
            "8/8 [==============================] - 0s 11ms/step - loss: 0.1591 - accuracy: 0.9973 - val_loss: 1.2364 - val_accuracy: 0.7377\n",
            "Epoch 166/300\n",
            "8/8 [==============================] - 0s 12ms/step - loss: 0.1473 - accuracy: 0.9966 - val_loss: 1.0707 - val_accuracy: 0.7869\n",
            "Epoch 167/300\n",
            "8/8 [==============================] - 0s 11ms/step - loss: 0.1567 - accuracy: 0.9880 - val_loss: 1.0686 - val_accuracy: 0.7705\n",
            "Epoch 168/300\n",
            "8/8 [==============================] - 0s 11ms/step - loss: 0.1448 - accuracy: 1.0000 - val_loss: 1.1147 - val_accuracy: 0.7541\n",
            "Epoch 169/300\n",
            "8/8 [==============================] - 0s 11ms/step - loss: 0.1743 - accuracy: 0.9837 - val_loss: 1.0460 - val_accuracy: 0.7705\n",
            "Epoch 170/300\n",
            "8/8 [==============================] - 0s 11ms/step - loss: 0.1795 - accuracy: 0.9868 - val_loss: 1.2334 - val_accuracy: 0.7377\n",
            "Epoch 171/300\n",
            "8/8 [==============================] - 0s 12ms/step - loss: 0.1428 - accuracy: 0.9936 - val_loss: 1.2524 - val_accuracy: 0.7377\n",
            "Epoch 172/300\n",
            "8/8 [==============================] - 0s 11ms/step - loss: 0.1507 - accuracy: 0.9935 - val_loss: 1.2682 - val_accuracy: 0.7541\n",
            "Epoch 173/300\n",
            "8/8 [==============================] - 0s 12ms/step - loss: 0.1574 - accuracy: 0.9926 - val_loss: 1.1177 - val_accuracy: 0.7869\n",
            "Epoch 174/300\n",
            "8/8 [==============================] - 0s 12ms/step - loss: 0.1888 - accuracy: 0.9838 - val_loss: 1.1306 - val_accuracy: 0.7869\n",
            "Epoch 175/300\n",
            "8/8 [==============================] - 0s 11ms/step - loss: 0.1670 - accuracy: 0.9840 - val_loss: 1.1524 - val_accuracy: 0.7869\n",
            "Epoch 176/300\n",
            "8/8 [==============================] - 0s 12ms/step - loss: 0.1512 - accuracy: 0.9953 - val_loss: 1.0730 - val_accuracy: 0.7705\n",
            "Epoch 177/300\n",
            "8/8 [==============================] - 0s 11ms/step - loss: 0.1615 - accuracy: 0.9953 - val_loss: 1.0019 - val_accuracy: 0.7541\n",
            "Epoch 178/300\n",
            "8/8 [==============================] - 0s 12ms/step - loss: 0.1603 - accuracy: 0.9936 - val_loss: 0.9608 - val_accuracy: 0.7705\n",
            "Epoch 179/300\n",
            "8/8 [==============================] - 0s 11ms/step - loss: 0.1396 - accuracy: 0.9986 - val_loss: 1.0157 - val_accuracy: 0.7541\n",
            "Epoch 180/300\n",
            "8/8 [==============================] - 0s 12ms/step - loss: 0.1608 - accuracy: 0.9862 - val_loss: 1.0707 - val_accuracy: 0.7541\n",
            "Epoch 181/300\n",
            "8/8 [==============================] - 0s 11ms/step - loss: 0.1392 - accuracy: 0.9991 - val_loss: 1.0706 - val_accuracy: 0.7541\n",
            "Epoch 182/300\n",
            "8/8 [==============================] - 0s 12ms/step - loss: 0.1350 - accuracy: 0.9973 - val_loss: 1.1658 - val_accuracy: 0.7869\n",
            "Epoch 183/300\n",
            "8/8 [==============================] - 0s 11ms/step - loss: 0.1780 - accuracy: 0.9936 - val_loss: 1.0990 - val_accuracy: 0.7705\n",
            "Epoch 184/300\n",
            "8/8 [==============================] - 0s 11ms/step - loss: 0.1344 - accuracy: 0.9973 - val_loss: 1.0104 - val_accuracy: 0.8033\n",
            "Epoch 185/300\n",
            "8/8 [==============================] - 0s 11ms/step - loss: 0.1290 - accuracy: 1.0000 - val_loss: 1.1046 - val_accuracy: 0.7377\n",
            "Epoch 186/300\n",
            "8/8 [==============================] - 0s 11ms/step - loss: 0.1753 - accuracy: 0.9746 - val_loss: 1.2155 - val_accuracy: 0.7705\n",
            "Epoch 187/300\n",
            "8/8 [==============================] - 0s 11ms/step - loss: 0.1506 - accuracy: 0.9908 - val_loss: 1.3386 - val_accuracy: 0.7377\n",
            "Epoch 188/300\n",
            "8/8 [==============================] - 0s 11ms/step - loss: 0.1678 - accuracy: 0.9845 - val_loss: 1.3376 - val_accuracy: 0.7377\n",
            "Epoch 189/300\n",
            "8/8 [==============================] - 0s 11ms/step - loss: 0.1581 - accuracy: 0.9874 - val_loss: 1.3698 - val_accuracy: 0.7869\n",
            "Epoch 190/300\n",
            "8/8 [==============================] - 0s 12ms/step - loss: 0.2585 - accuracy: 0.9640 - val_loss: 1.1270 - val_accuracy: 0.7705\n",
            "Epoch 191/300\n",
            "8/8 [==============================] - 0s 11ms/step - loss: 0.1463 - accuracy: 0.9972 - val_loss: 1.0456 - val_accuracy: 0.8033\n",
            "Epoch 192/300\n",
            "8/8 [==============================] - 0s 11ms/step - loss: 0.1552 - accuracy: 0.9939 - val_loss: 1.1933 - val_accuracy: 0.7541\n",
            "Epoch 193/300\n",
            "8/8 [==============================] - 0s 11ms/step - loss: 0.1477 - accuracy: 0.9980 - val_loss: 1.2442 - val_accuracy: 0.7541\n",
            "Epoch 194/300\n",
            "8/8 [==============================] - 0s 11ms/step - loss: 0.1422 - accuracy: 1.0000 - val_loss: 1.2728 - val_accuracy: 0.7213\n",
            "Epoch 195/300\n",
            "8/8 [==============================] - 0s 11ms/step - loss: 0.1468 - accuracy: 0.9953 - val_loss: 1.2027 - val_accuracy: 0.7377\n",
            "Epoch 196/300\n",
            "8/8 [==============================] - 0s 11ms/step - loss: 0.1335 - accuracy: 1.0000 - val_loss: 1.1682 - val_accuracy: 0.7705\n",
            "Epoch 197/300\n",
            "8/8 [==============================] - 0s 11ms/step - loss: 0.1326 - accuracy: 1.0000 - val_loss: 1.1489 - val_accuracy: 0.7705\n",
            "Epoch 198/300\n",
            "8/8 [==============================] - 0s 11ms/step - loss: 0.1360 - accuracy: 0.9964 - val_loss: 1.1474 - val_accuracy: 0.7541\n",
            "Epoch 199/300\n",
            "8/8 [==============================] - 0s 11ms/step - loss: 0.1236 - accuracy: 1.0000 - val_loss: 1.1481 - val_accuracy: 0.7869\n",
            "Epoch 200/300\n",
            "8/8 [==============================] - 0s 11ms/step - loss: 0.1276 - accuracy: 0.9950 - val_loss: 1.1746 - val_accuracy: 0.7541\n",
            "Epoch 201/300\n",
            "8/8 [==============================] - 0s 11ms/step - loss: 0.1177 - accuracy: 1.0000 - val_loss: 1.2179 - val_accuracy: 0.7541\n",
            "Epoch 202/300\n",
            "8/8 [==============================] - 0s 11ms/step - loss: 0.1192 - accuracy: 1.0000 - val_loss: 1.2631 - val_accuracy: 0.7377\n",
            "Epoch 203/300\n",
            "8/8 [==============================] - 0s 12ms/step - loss: 0.1184 - accuracy: 0.9945 - val_loss: 1.2122 - val_accuracy: 0.7377\n",
            "Epoch 204/300\n",
            "8/8 [==============================] - 0s 11ms/step - loss: 0.1183 - accuracy: 0.9936 - val_loss: 1.1772 - val_accuracy: 0.7869\n",
            "Epoch 205/300\n",
            "8/8 [==============================] - 0s 11ms/step - loss: 0.1151 - accuracy: 0.9977 - val_loss: 1.1858 - val_accuracy: 0.7869\n",
            "Epoch 206/300\n",
            "8/8 [==============================] - 0s 12ms/step - loss: 0.1131 - accuracy: 0.9986 - val_loss: 1.2247 - val_accuracy: 0.7541\n",
            "Epoch 207/300\n",
            "8/8 [==============================] - 0s 11ms/step - loss: 0.1399 - accuracy: 0.9959 - val_loss: 1.2649 - val_accuracy: 0.7377\n",
            "Epoch 208/300\n",
            "8/8 [==============================] - 0s 11ms/step - loss: 0.1486 - accuracy: 0.9897 - val_loss: 1.2317 - val_accuracy: 0.7705\n",
            "Epoch 209/300\n",
            "8/8 [==============================] - 0s 11ms/step - loss: 0.1423 - accuracy: 0.9869 - val_loss: 1.3679 - val_accuracy: 0.7869\n",
            "Epoch 210/300\n",
            "8/8 [==============================] - 0s 11ms/step - loss: 0.2090 - accuracy: 0.9740 - val_loss: 1.3286 - val_accuracy: 0.7541\n",
            "Epoch 211/300\n",
            "8/8 [==============================] - 0s 11ms/step - loss: 0.1640 - accuracy: 0.9826 - val_loss: 1.2073 - val_accuracy: 0.7541\n",
            "Epoch 212/300\n",
            "8/8 [==============================] - 0s 11ms/step - loss: 0.1754 - accuracy: 0.9828 - val_loss: 1.4574 - val_accuracy: 0.7377\n",
            "Epoch 213/300\n",
            "8/8 [==============================] - 0s 11ms/step - loss: 0.2417 - accuracy: 0.9630 - val_loss: 1.3555 - val_accuracy: 0.7541\n",
            "Epoch 214/300\n",
            "8/8 [==============================] - 0s 11ms/step - loss: 0.1496 - accuracy: 0.9950 - val_loss: 1.4571 - val_accuracy: 0.7377\n",
            "Epoch 215/300\n",
            "8/8 [==============================] - 0s 11ms/step - loss: 0.1688 - accuracy: 0.9971 - val_loss: 1.4221 - val_accuracy: 0.7541\n",
            "Epoch 216/300\n",
            "8/8 [==============================] - 0s 11ms/step - loss: 0.1370 - accuracy: 1.0000 - val_loss: 1.3302 - val_accuracy: 0.7541\n",
            "Epoch 217/300\n",
            "8/8 [==============================] - 0s 11ms/step - loss: 0.1326 - accuracy: 1.0000 - val_loss: 1.2894 - val_accuracy: 0.7705\n",
            "Epoch 218/300\n",
            "8/8 [==============================] - 0s 11ms/step - loss: 0.1282 - accuracy: 1.0000 - val_loss: 1.2716 - val_accuracy: 0.7705\n",
            "Epoch 219/300\n",
            "8/8 [==============================] - 0s 11ms/step - loss: 0.1390 - accuracy: 0.9916 - val_loss: 1.3107 - val_accuracy: 0.7705\n",
            "Epoch 220/300\n",
            "8/8 [==============================] - 0s 12ms/step - loss: 0.1254 - accuracy: 0.9964 - val_loss: 1.2531 - val_accuracy: 0.7541\n",
            "Epoch 221/300\n",
            "8/8 [==============================] - 0s 11ms/step - loss: 0.1197 - accuracy: 1.0000 - val_loss: 1.2161 - val_accuracy: 0.7377\n",
            "Epoch 222/300\n",
            "8/8 [==============================] - 0s 11ms/step - loss: 0.1284 - accuracy: 0.9957 - val_loss: 1.1627 - val_accuracy: 0.7541\n",
            "Epoch 223/300\n",
            "8/8 [==============================] - 0s 11ms/step - loss: 0.1487 - accuracy: 0.9936 - val_loss: 1.0727 - val_accuracy: 0.7377\n",
            "Epoch 224/300\n",
            "8/8 [==============================] - 0s 11ms/step - loss: 0.1942 - accuracy: 0.9733 - val_loss: 1.3058 - val_accuracy: 0.7049\n",
            "Epoch 225/300\n",
            "8/8 [==============================] - 0s 11ms/step - loss: 0.1259 - accuracy: 0.9950 - val_loss: 1.2898 - val_accuracy: 0.7213\n",
            "Epoch 226/300\n",
            "8/8 [==============================] - 0s 11ms/step - loss: 0.1358 - accuracy: 0.9856 - val_loss: 1.0785 - val_accuracy: 0.7541\n",
            "Epoch 227/300\n",
            "8/8 [==============================] - 0s 12ms/step - loss: 0.1236 - accuracy: 0.9991 - val_loss: 1.0471 - val_accuracy: 0.7377\n",
            "Epoch 228/300\n",
            "8/8 [==============================] - 0s 11ms/step - loss: 0.1497 - accuracy: 0.9791 - val_loss: 1.2075 - val_accuracy: 0.7705\n",
            "Epoch 229/300\n",
            "8/8 [==============================] - 0s 11ms/step - loss: 0.2099 - accuracy: 0.9625 - val_loss: 1.1909 - val_accuracy: 0.7377\n",
            "Epoch 230/300\n",
            "8/8 [==============================] - 0s 11ms/step - loss: 0.1522 - accuracy: 0.9855 - val_loss: 1.1857 - val_accuracy: 0.7869\n",
            "Epoch 231/300\n",
            "8/8 [==============================] - 0s 11ms/step - loss: 0.1691 - accuracy: 0.9903 - val_loss: 1.2104 - val_accuracy: 0.7869\n",
            "Epoch 232/300\n",
            "8/8 [==============================] - 0s 11ms/step - loss: 0.1513 - accuracy: 0.9901 - val_loss: 1.1367 - val_accuracy: 0.7541\n",
            "Epoch 233/300\n",
            "8/8 [==============================] - 0s 11ms/step - loss: 0.1513 - accuracy: 0.9906 - val_loss: 1.1385 - val_accuracy: 0.7705\n",
            "Epoch 234/300\n",
            "8/8 [==============================] - 0s 11ms/step - loss: 0.1294 - accuracy: 0.9982 - val_loss: 1.1808 - val_accuracy: 0.7705\n",
            "Epoch 235/300\n",
            "8/8 [==============================] - 0s 11ms/step - loss: 0.1285 - accuracy: 0.9991 - val_loss: 1.2274 - val_accuracy: 0.7377\n",
            "Epoch 236/300\n",
            "8/8 [==============================] - 0s 11ms/step - loss: 0.1429 - accuracy: 0.9909 - val_loss: 1.1634 - val_accuracy: 0.7869\n",
            "Epoch 237/300\n",
            "8/8 [==============================] - 0s 11ms/step - loss: 0.1380 - accuracy: 0.9903 - val_loss: 1.0982 - val_accuracy: 0.7869\n",
            "Epoch 238/300\n",
            "8/8 [==============================] - 0s 11ms/step - loss: 0.2222 - accuracy: 0.9608 - val_loss: 1.2204 - val_accuracy: 0.7705\n",
            "Epoch 239/300\n",
            "8/8 [==============================] - 0s 11ms/step - loss: 0.1258 - accuracy: 0.9971 - val_loss: 1.2471 - val_accuracy: 0.7705\n",
            "Epoch 240/300\n",
            "8/8 [==============================] - 0s 11ms/step - loss: 0.1386 - accuracy: 0.9903 - val_loss: 1.1639 - val_accuracy: 0.8197\n",
            "Epoch 241/300\n",
            "8/8 [==============================] - 0s 11ms/step - loss: 0.1209 - accuracy: 1.0000 - val_loss: 1.1519 - val_accuracy: 0.8033\n",
            "Epoch 242/300\n",
            "8/8 [==============================] - 0s 11ms/step - loss: 0.1182 - accuracy: 1.0000 - val_loss: 1.1605 - val_accuracy: 0.7869\n",
            "Epoch 243/300\n",
            "8/8 [==============================] - 0s 11ms/step - loss: 0.1246 - accuracy: 0.9953 - val_loss: 1.3137 - val_accuracy: 0.7541\n",
            "Epoch 244/300\n",
            "8/8 [==============================] - 0s 11ms/step - loss: 0.1176 - accuracy: 1.0000 - val_loss: 1.4290 - val_accuracy: 0.7541\n",
            "Epoch 245/300\n",
            "8/8 [==============================] - 0s 11ms/step - loss: 0.1132 - accuracy: 0.9973 - val_loss: 1.3314 - val_accuracy: 0.7541\n",
            "Epoch 246/300\n",
            "8/8 [==============================] - 0s 11ms/step - loss: 0.1098 - accuracy: 1.0000 - val_loss: 1.2461 - val_accuracy: 0.7705\n",
            "Epoch 247/300\n",
            "8/8 [==============================] - 0s 11ms/step - loss: 0.1085 - accuracy: 0.9973 - val_loss: 1.2325 - val_accuracy: 0.7541\n",
            "Epoch 248/300\n",
            "8/8 [==============================] - 0s 11ms/step - loss: 0.1055 - accuracy: 1.0000 - val_loss: 1.3033 - val_accuracy: 0.7541\n",
            "Epoch 249/300\n",
            "8/8 [==============================] - 0s 11ms/step - loss: 0.0994 - accuracy: 1.0000 - val_loss: 1.3177 - val_accuracy: 0.7377\n",
            "Epoch 250/300\n",
            "8/8 [==============================] - 0s 11ms/step - loss: 0.0988 - accuracy: 1.0000 - val_loss: 1.3141 - val_accuracy: 0.7541\n",
            "Epoch 251/300\n",
            "8/8 [==============================] - 0s 11ms/step - loss: 0.0959 - accuracy: 1.0000 - val_loss: 1.2911 - val_accuracy: 0.7541\n",
            "Epoch 252/300\n",
            "8/8 [==============================] - 0s 11ms/step - loss: 0.0934 - accuracy: 1.0000 - val_loss: 1.2523 - val_accuracy: 0.7541\n",
            "Epoch 253/300\n",
            "8/8 [==============================] - 0s 11ms/step - loss: 0.0919 - accuracy: 1.0000 - val_loss: 1.2080 - val_accuracy: 0.7541\n",
            "Epoch 254/300\n",
            "8/8 [==============================] - 0s 11ms/step - loss: 0.0898 - accuracy: 1.0000 - val_loss: 1.1851 - val_accuracy: 0.7541\n",
            "Epoch 255/300\n",
            "8/8 [==============================] - 0s 11ms/step - loss: 0.0880 - accuracy: 1.0000 - val_loss: 1.1820 - val_accuracy: 0.7705\n",
            "Epoch 256/300\n",
            "8/8 [==============================] - 0s 11ms/step - loss: 0.0852 - accuracy: 1.0000 - val_loss: 1.1675 - val_accuracy: 0.7705\n",
            "Epoch 257/300\n",
            "8/8 [==============================] - 0s 11ms/step - loss: 0.0859 - accuracy: 1.0000 - val_loss: 1.1171 - val_accuracy: 0.7705\n",
            "Epoch 258/300\n",
            "8/8 [==============================] - 0s 11ms/step - loss: 0.0832 - accuracy: 1.0000 - val_loss: 1.0513 - val_accuracy: 0.8033\n",
            "Epoch 259/300\n",
            "8/8 [==============================] - 0s 12ms/step - loss: 0.0810 - accuracy: 1.0000 - val_loss: 1.0188 - val_accuracy: 0.8033\n",
            "Epoch 260/300\n",
            "8/8 [==============================] - 0s 11ms/step - loss: 0.0785 - accuracy: 1.0000 - val_loss: 1.0264 - val_accuracy: 0.8033\n",
            "Epoch 261/300\n",
            "8/8 [==============================] - 0s 12ms/step - loss: 0.0763 - accuracy: 1.0000 - val_loss: 1.0481 - val_accuracy: 0.7869\n",
            "Epoch 262/300\n",
            "8/8 [==============================] - 0s 11ms/step - loss: 0.0745 - accuracy: 1.0000 - val_loss: 1.0507 - val_accuracy: 0.7869\n",
            "Epoch 263/300\n",
            "8/8 [==============================] - 0s 12ms/step - loss: 0.0730 - accuracy: 1.0000 - val_loss: 1.0448 - val_accuracy: 0.7869\n",
            "Epoch 264/300\n",
            "8/8 [==============================] - 0s 11ms/step - loss: 0.0716 - accuracy: 1.0000 - val_loss: 1.0394 - val_accuracy: 0.7705\n",
            "Epoch 265/300\n",
            "8/8 [==============================] - 0s 11ms/step - loss: 0.0706 - accuracy: 1.0000 - val_loss: 1.0311 - val_accuracy: 0.7705\n",
            "Epoch 266/300\n",
            "8/8 [==============================] - 0s 11ms/step - loss: 0.0699 - accuracy: 1.0000 - val_loss: 1.0112 - val_accuracy: 0.7869\n",
            "Epoch 267/300\n",
            "8/8 [==============================] - 0s 11ms/step - loss: 0.0678 - accuracy: 1.0000 - val_loss: 1.0021 - val_accuracy: 0.7869\n",
            "Epoch 268/300\n",
            "8/8 [==============================] - 0s 12ms/step - loss: 0.1484 - accuracy: 0.9694 - val_loss: 1.0148 - val_accuracy: 0.7869\n",
            "Epoch 269/300\n",
            "8/8 [==============================] - 0s 11ms/step - loss: 0.1284 - accuracy: 0.9824 - val_loss: 1.0404 - val_accuracy: 0.7705\n",
            "Epoch 270/300\n",
            "8/8 [==============================] - 0s 11ms/step - loss: 0.1325 - accuracy: 0.9923 - val_loss: 1.3408 - val_accuracy: 0.7705\n",
            "Epoch 271/300\n",
            "8/8 [==============================] - 0s 11ms/step - loss: 0.1496 - accuracy: 0.9900 - val_loss: 1.5014 - val_accuracy: 0.7213\n",
            "Epoch 272/300\n",
            "8/8 [==============================] - 0s 12ms/step - loss: 0.1570 - accuracy: 0.9938 - val_loss: 1.5646 - val_accuracy: 0.7705\n",
            "Epoch 273/300\n",
            "8/8 [==============================] - 0s 12ms/step - loss: 0.2039 - accuracy: 0.9802 - val_loss: 1.4889 - val_accuracy: 0.7541\n",
            "Epoch 274/300\n",
            "8/8 [==============================] - 0s 12ms/step - loss: 0.1943 - accuracy: 0.9762 - val_loss: 1.4216 - val_accuracy: 0.7541\n",
            "Epoch 275/300\n",
            "8/8 [==============================] - 0s 11ms/step - loss: 0.1628 - accuracy: 0.9915 - val_loss: 1.4920 - val_accuracy: 0.7377\n",
            "Epoch 276/300\n",
            "8/8 [==============================] - 0s 11ms/step - loss: 0.1642 - accuracy: 0.9877 - val_loss: 1.5638 - val_accuracy: 0.7541\n",
            "Epoch 277/300\n",
            "8/8 [==============================] - 0s 11ms/step - loss: 0.1825 - accuracy: 0.9798 - val_loss: 1.2233 - val_accuracy: 0.7541\n",
            "Epoch 278/300\n",
            "8/8 [==============================] - 0s 11ms/step - loss: 0.1778 - accuracy: 0.9903 - val_loss: 1.2095 - val_accuracy: 0.7869\n",
            "Epoch 279/300\n",
            "8/8 [==============================] - 0s 11ms/step - loss: 0.1983 - accuracy: 0.9782 - val_loss: 1.3649 - val_accuracy: 0.7869\n",
            "Epoch 280/300\n",
            "8/8 [==============================] - 0s 11ms/step - loss: 0.1711 - accuracy: 0.9833 - val_loss: 1.4721 - val_accuracy: 0.7377\n",
            "Epoch 281/300\n",
            "8/8 [==============================] - 0s 11ms/step - loss: 0.1472 - accuracy: 0.9953 - val_loss: 1.5081 - val_accuracy: 0.7213\n",
            "Epoch 282/300\n",
            "8/8 [==============================] - 0s 11ms/step - loss: 0.1438 - accuracy: 0.9935 - val_loss: 1.3714 - val_accuracy: 0.7377\n",
            "Epoch 283/300\n",
            "8/8 [==============================] - 0s 12ms/step - loss: 0.1417 - accuracy: 0.9980 - val_loss: 1.4295 - val_accuracy: 0.7869\n",
            "Epoch 284/300\n",
            "8/8 [==============================] - 0s 10ms/step - loss: 0.1379 - accuracy: 0.9982 - val_loss: 1.4855 - val_accuracy: 0.7705\n",
            "Epoch 285/300\n",
            "8/8 [==============================] - 0s 11ms/step - loss: 0.1742 - accuracy: 0.9829 - val_loss: 1.6393 - val_accuracy: 0.7705\n",
            "Epoch 286/300\n",
            "8/8 [==============================] - 0s 12ms/step - loss: 0.1817 - accuracy: 0.9817 - val_loss: 1.5096 - val_accuracy: 0.7705\n",
            "Epoch 287/300\n",
            "8/8 [==============================] - 0s 12ms/step - loss: 0.1519 - accuracy: 0.9874 - val_loss: 1.4975 - val_accuracy: 0.7377\n",
            "Epoch 288/300\n",
            "8/8 [==============================] - 0s 12ms/step - loss: 0.1462 - accuracy: 0.9944 - val_loss: 1.4110 - val_accuracy: 0.7705\n",
            "Epoch 289/300\n",
            "8/8 [==============================] - 0s 11ms/step - loss: 0.1518 - accuracy: 0.9874 - val_loss: 1.4247 - val_accuracy: 0.7705\n",
            "Epoch 290/300\n",
            "8/8 [==============================] - 0s 11ms/step - loss: 0.1269 - accuracy: 1.0000 - val_loss: 1.4385 - val_accuracy: 0.7705\n",
            "Epoch 291/300\n",
            "8/8 [==============================] - 0s 12ms/step - loss: 0.1273 - accuracy: 1.0000 - val_loss: 1.4242 - val_accuracy: 0.7705\n",
            "Epoch 292/300\n",
            "8/8 [==============================] - 0s 11ms/step - loss: 0.1191 - accuracy: 1.0000 - val_loss: 1.4011 - val_accuracy: 0.7705\n",
            "Epoch 293/300\n",
            "8/8 [==============================] - 0s 11ms/step - loss: 0.1783 - accuracy: 0.9826 - val_loss: 1.2198 - val_accuracy: 0.8033\n",
            "Epoch 294/300\n",
            "8/8 [==============================] - 0s 11ms/step - loss: 0.1567 - accuracy: 0.9835 - val_loss: 1.1290 - val_accuracy: 0.7869\n",
            "Epoch 295/300\n",
            "8/8 [==============================] - 0s 11ms/step - loss: 0.1133 - accuracy: 1.0000 - val_loss: 1.1401 - val_accuracy: 0.7541\n",
            "Epoch 296/300\n",
            "8/8 [==============================] - 0s 12ms/step - loss: 0.1554 - accuracy: 0.9766 - val_loss: 1.2563 - val_accuracy: 0.7705\n",
            "Epoch 297/300\n",
            "8/8 [==============================] - 0s 11ms/step - loss: 0.1115 - accuracy: 0.9980 - val_loss: 1.3151 - val_accuracy: 0.7705\n",
            "Epoch 298/300\n",
            "8/8 [==============================] - 0s 11ms/step - loss: 0.1148 - accuracy: 0.9980 - val_loss: 1.2795 - val_accuracy: 0.7705\n",
            "Epoch 299/300\n",
            "8/8 [==============================] - 0s 11ms/step - loss: 0.1043 - accuracy: 1.0000 - val_loss: 1.2064 - val_accuracy: 0.7705\n",
            "Epoch 300/300\n",
            "8/8 [==============================] - 0s 11ms/step - loss: 0.1042 - accuracy: 1.0000 - val_loss: 1.1380 - val_accuracy: 0.7705\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 282
        },
        "id": "nzlmht_oobhg",
        "outputId": "7958a5ae-b3ac-4574-e581-23b293a2acc0"
      },
      "source": [
        "plt.plot(history.history[\"accuracy\"])\n",
        "plt.plot(history.history[\"val_accuracy\"])"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[<matplotlib.lines.Line2D at 0x7fe53be1bc90>]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 24
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "QK3V28MlVwoz",
        "outputId": "8bc9f184-0ffe-4040-8e0d-e1b8dec18fce"
      },
      "source": [
        "y_dnn_pred = model.predict_classes(X_test)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/tensorflow/python/keras/engine/sequential.py:450: UserWarning: `model.predict_classes()` is deprecated and will be removed after 2021-01-01. Please use instead:* `np.argmax(model.predict(x), axis=-1)`,   if your model does multi-class classification   (e.g. if it uses a `softmax` last-layer activation).* `(model.predict(x) > 0.5).astype(\"int32\")`,   if your model does binary classification   (e.g. if it uses a `sigmoid` last-layer activation).\n",
            "  warnings.warn('`model.predict_classes()` is deprecated and '\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9bYqAtRQWEir"
      },
      "source": [
        "y_dnn_pred = np.squeeze(y_dnn_pred)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "c2vjsIJWV_Wm",
        "outputId": "0656a2de-29a2-4fac-9a6d-00d30dd19a08"
      },
      "source": [
        "print(\"Accuracy:\",metrics.accuracy_score(y_test, y_dnn_pred))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Accuracy: 0.7704918032786885\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2Wa7trnhIemX"
      },
      "source": [
        "## Support Vector Machine"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Lz53SCT9IeHV"
      },
      "source": [
        "from sklearn import svm\n",
        "from sklearn.model_selection import GridSearchCV"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6z0f5oodL07r"
      },
      "source": [
        "param_grid = {'C': [0.1,1, 10, 100], 'gamma': [1,0.1,0.01,0.001],'kernel': ['rbf', 'poly', 'sigmoid']}"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "u7MEg80eL5ku",
        "outputId": "7c3c5bee-c734-4c14-85ac-1c6d22a0ea7c"
      },
      "source": [
        "grid = GridSearchCV(svm.SVC(),param_grid,refit=True,verbose=0)\n",
        "grid.fit(X_train,y_train)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "GridSearchCV(cv=None, error_score=nan,\n",
              "             estimator=SVC(C=1.0, break_ties=False, cache_size=200,\n",
              "                           class_weight=None, coef0=0.0,\n",
              "                           decision_function_shape='ovr', degree=3,\n",
              "                           gamma='scale', kernel='rbf', max_iter=-1,\n",
              "                           probability=False, random_state=None, shrinking=True,\n",
              "                           tol=0.001, verbose=False),\n",
              "             iid='deprecated', n_jobs=None,\n",
              "             param_grid={'C': [0.1, 1, 10, 100], 'gamma': [1, 0.1, 0.01, 0.001],\n",
              "                         'kernel': ['rbf', 'poly', 'sigmoid']},\n",
              "             pre_dispatch='2*n_jobs', refit=True, return_train_score=False,\n",
              "             scoring=None, verbose=0)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 30
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "u4P32_9aL_tx"
      },
      "source": [
        "print(grid.best_estimator_)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "z0s-jSDBMC7K"
      },
      "source": [
        "clf = svm.SVC(C=10, break_ties=False, cache_size=200, class_weight=None, coef0=0.0,\n",
        "    decision_function_shape='ovr', degree=3, gamma=0.1, kernel='sigmoid',\n",
        "    max_iter=-1, probability=False, random_state=None, shrinking=True,\n",
        "    tol=0.001, verbose=False)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zV90gd3jIpDH"
      },
      "source": [
        "clf.fit(X_train, y_train)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "k-l6rFkgKixZ"
      },
      "source": [
        "y_svm_pred = clf.predict(X_test)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "C6ogiJM_KeP-"
      },
      "source": [
        "print(\"Accuracy:\",metrics.accuracy_score(y_test, y_svm_pred))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zQg7KS93MTOl"
      },
      "source": [
        "## Random Forest"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "eRRomm4SMSrH"
      },
      "source": [
        "from sklearn.ensemble import RandomForestClassifier"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "evi3ZjHCM235"
      },
      "source": [
        "#param_grid = {'max_depth': [80, 90, 100, 110],\n",
        "#              'min_samples_leaf': [3, 4, 5],\n",
        "#              'min_samples_split': [8, 10, 12],\n",
        "#              'n_estimators': [100, 200, 300, 1000]}"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "I2T7UyI9NDU9"
      },
      "source": [
        "#grid = GridSearchCV(RandomForestClassifier(),param_grid,refit=True,verbose=2)\n",
        "#grid.fit(X,y)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "AoFHgLC8NZ8o"
      },
      "source": [
        "#print(grid.best_estimator_)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Im-bncEOQQTl"
      },
      "source": [
        "clf = RandomForestClassifier()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3tsRlJ-UMi5T"
      },
      "source": [
        "clf.fit(X_train_tree, y_train_tree)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "N-bjDHn4MitE"
      },
      "source": [
        "y_rf_pred = clf.predict(X_test_tree)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Wd04W1mkMiav"
      },
      "source": [
        "print(\"Accuracy:\",metrics.accuracy_score(y_test_tree, y_rf_pred))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "CjGqlBftQguH"
      },
      "source": [
        "## Adaboost"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bjdy88eqQAua"
      },
      "source": [
        "from sklearn.ensemble import AdaBoostClassifier"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Tkz3SOurQjEz"
      },
      "source": [
        "clf = AdaBoostClassifier(n_estimators=100, random_state=0)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "iUTqXNllQnNa"
      },
      "source": [
        "clf.fit(X_train, y_train)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Op8vbR8HQo3c"
      },
      "source": [
        "y_ada_pred = clf.predict(X_test)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_iKFEPDcQrQy"
      },
      "source": [
        "print(\"Accuracy:\",metrics.accuracy_score(y_test, y_ada_pred))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Lm3ViWysRIJD"
      },
      "source": [
        "## Gradient Boosting"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "iZuWF0cuQtyc"
      },
      "source": [
        "from sklearn.ensemble import GradientBoostingClassifier"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qcMS4uKiRNYS"
      },
      "source": [
        "clf = GradientBoostingClassifier(n_estimators=100, learning_rate=1.0, max_depth=1, random_state=0)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kGbz0JDaRfDN"
      },
      "source": [
        "clf.fit(X_train, y_train)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XSOuwL7cRi_i"
      },
      "source": [
        "y_gb_pred = clf.predict(X_test)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HLxcWvjNRmW2"
      },
      "source": [
        "print(\"Accuracy:\",metrics.accuracy_score(y_test, y_gb_pred))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "MCRUJZFtS7UU"
      },
      "source": [
        "## Logistic Regression"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hL5kfLWsSejl"
      },
      "source": [
        "from sklearn.linear_model import LogisticRegression"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GS9hVIxOS-uA"
      },
      "source": [
        "clf = LogisticRegression(random_state=0)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QnYSI7aATCCP"
      },
      "source": [
        "clf.fit(X_train, y_train)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FU5Po1UXTTLC"
      },
      "source": [
        "y_logistic_pred = clf.predict(X_test)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MSbt8pmITnQC"
      },
      "source": [
        "print(\"Accuracy:\",metrics.accuracy_score(y_test, y_logistic_pred))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fjJzb3RVdgUi"
      },
      "source": [
        "# To Do List\n",
        "from sklearn.neighbors import KNeighborsClassifier\n",
        "from sklearn.naive_bayes import BernoulliNB\n",
        "from sklearn.naive_bayes import GaussianNB"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "43Jsecx-aSkd"
      },
      "source": [
        "from sklearn.metrics import confusion_matrix"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "YsfElX47gIBf"
      },
      "source": [
        "## Gaussian Naive Bayes"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qSGOqMG5d8dc"
      },
      "source": [
        "clf = GaussianNB()\n",
        "clf.fit(X_train, y_train)\n",
        "  \n",
        "y_Gaussian_pred = clf.predict(X_test)\n",
        "\n",
        "print(\"Accuracy of Gaussian Naive Bayes:\", round(metrics.accuracy_score(y_test, y_Gaussian_pred),3))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ch3H79akgOFZ"
      },
      "source": [
        "## Bernoulli Naive Bayes"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2p7JeK3yemAp"
      },
      "source": [
        "clf = BernoulliNB()\n",
        "clf.fit(X_train, y_train)\n",
        "  \n",
        "y_Bernoulli_pred = clf.predict(X_test)\n",
        "  \n",
        "print(\"The accuracy of Bernoulli Naive Bayes: \", round(metrics.accuracy_score(y_test, y_Bernoulli_pred),3))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1SSaWiExggji"
      },
      "source": [
        "## K Nearest Neighbours"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FTzdhiGVfP_n"
      },
      "source": [
        "clf = KNeighborsClassifier(n_neighbors = 1)  \n",
        "clf.fit(X_train, y_train)\n",
        "\n",
        "y_KNeighbors_pred = model.predict(X_test).round()\n",
        "\n",
        "print(\"The accuracy of K Nearest Neighbours : \", round(metrics.accuracy_score(y_test, y_KNeighbors_pred),3))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Dmyay26bT0X_"
      },
      "source": [
        "# Summary"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-qHASpJ7TzQ5"
      },
      "source": [
        "names = [\"Deep Neural Network\", \"Support Vector Machine\", \"Random Forest\", \"Adaboost\",\"Gradient Boost\",\"Logistic Regression\",\n",
        "         \"Gaussian Naive Bayes\", \"Bernoulli Naive Bayes\",\"K Nearest Neighbours\"]\n",
        "\n",
        "predictions = [y_dnn_pred, y_svm_pred, y_rf_pred, y_ada_pred, y_gb_pred, y_logistic_pred, y_Gaussian_pred,\n",
        "               y_Bernoulli_pred, y_KNeighbors_pred]\n",
        "\n",
        "acc_list = []\n",
        "for i in range(len(names)):\n",
        "  score = metrics.accuracy_score(y_test,predictions[i])\n",
        "  print(\"Accuracy of\",names[i], \":\", round(score,3))\n",
        "  acc_list.append(score)\n",
        "\n",
        "index_max = np.argmax(acc_list)\n",
        "print(\"\\n\")\n",
        "print(\"The best model is << {0} >> with accuracy:{1}\".format(names[index_max],round(acc_list[index_max],3)))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "AlbgzK1Yfp8C"
      },
      "source": [
        "#error_rate = []\n",
        "#  \n",
        "#for i in range(1, 40):\n",
        "#      \n",
        "#    model = KNeighborsClassifier(n_neighbors = i)\n",
        "#    model.fit(x_train, y_train)\n",
        "#    pred_i = model.predict(x_test)\n",
        "#    error_rate.append(np.mean(pred_i != y_test))\n",
        "  \n",
        "#plt.figure(figsize =(10, 6))\n",
        "#plt.plot(range(1, 40), error_rate, color ='blue',\n",
        "#                linestyle ='dashed', marker ='o',\n",
        "#         markerfacecolor ='red', markersize = 10)\n",
        "  \n",
        "#plt.title('Error Rate vs. K Value')\n",
        "#plt.xlabel('K')\n",
        "#plt.ylabel('Error Rate')"
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}
